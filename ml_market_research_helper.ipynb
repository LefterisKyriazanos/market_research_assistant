{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# from huggingface_hub import HfApic\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "# from langchain.agents import load_tools\n",
    "# from langchain.agents import initialize_agent\n",
    "# from langchain.agents import AgentType\n",
    "# from langchain.agents.load_tools import get_all_tool_names\n",
    "# from langchain import ConversationChain\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "import prompt_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate costs \n",
    "- input of around 1000 tokens costs $0.0015, so 100 tokens (per req) should cost $0.00015\n",
    "- 1000 queries of 100 tokens each should cost around 0,15$ for input processing \n",
    "- output of around 1000 tokens costs $0.0020, so 250 tokens (per req) should cost $0.0005\n",
    "-  1000 queries of 250 output tokens each should cost around 0,5$ in output fees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks for a .env file with OPENAI_API_KEY & HUGGING_FACE_API_TOKEN\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['industry', 'product'] template='You are a professional market researcher working in the {industry} industry. You want to know how people feel about {product}.\\nIn order to perform market research you need to define 10 statements to which the users will respond on a scale 1-5.\\n1 means strongly disagree while 5 means strongly agree.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lefos/Desktop/market_research_assistant/.venv/lib/python3.9/site-packages/langchain_community/llms/openai.py:249: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/lefos/Desktop/market_research_assistant/.venv/lib/python3.9/site-packages/langchain_community/llms/openai.py:1070: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# user defined \n",
    "\n",
    "industry = 'car manufacturing'\n",
    "product = 'electric cars'\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# LLMs: Get predictions from a language model\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0.7)\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Chains: Combine LLMs and prompts in multi-step workflows\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"industry\",\"product\"],\n",
    "    template=prompt_templates.prompt_msg,\n",
    ")\n",
    "print(prompt)\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'industry': 'car manufacturing', 'product': 'electric cars', 'text': '1. Electric cars are a more environmentally friendly option compared to traditional gasoline cars.\\n2. I am concerned about the limited range of electric cars compared to gasoline cars.\\n3. I believe electric cars are more cost-effective in the long run due to lower maintenance and fuel costs.\\n4. Electric cars have advanced enough in technology to be a viable option for everyday use.\\n5. I am worried about the availability of charging stations for electric cars in my area.\\n6. I believe electric cars are the future of the automotive industry.\\n7. I am hesitant to switch to an electric car because of concerns about battery life and replacement costs.\\n8. Electric cars offer a smoother and quieter driving experience compared to gasoline cars.\\n9. I am willing to pay a premium price for an electric car in order to contribute to reducing carbon emissions.\\n10. I am concerned about the environmental impact of producing the batteries used in electric cars.'}\n"
     ]
    }
   ],
   "source": [
    "# call chatbot\n",
    "response = chain.invoke(input={'industry':industry, 'product':product})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Electric cars are a more environmentally friendly option compared to traditional gasoline cars.\\n2. I am concerned about the limited range of electric cars compared to gasoline cars.\\n3. I believe electric cars are more cost-effective in the long run due to lower maintenance and fuel costs.\\n4. Electric cars have advanced enough in technology to be a viable option for everyday use.\\n5. I am worried about the availability of charging stations for electric cars in my area.\\n6. I believe electric cars are the future of the automotive industry.\\n7. I am hesitant to switch to an electric car because of concerns about battery life and replacement costs.\\n8. Electric cars offer a smoother and quieter driving experience compared to gasoline cars.\\n9. I am willing to pay a premium price for an electric car in order to contribute to reducing carbon emissions.\\n10. I am concerned about the environmental impact of producing the batteries used in electric cars.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_response = response['text']\n",
    "text_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
